# ***********************************************************************************************
# Title   : 統計的因果推論の理論と実装
# Chapter : 7 最小二乗法によるモデリングと診断1
# Date    : 2022/11/23
# Page    : P90 - P106
# URL     : https://github.com/mtakahashi123/causality
# ***********************************************************************************************


# ＜概要＞
# - 回帰分析は複数の仮定の元に成立しており、使用する際には仮定が満たされているかの確認が必要
#   --- データ変換などによって仮定を成立させれるケースがある
#   --- 仮定が担保できないことに対するソリューションを考える学問分野が多数ある（計量経済学など）


# ＜回帰分析の仮定＞
# - 仮定1： 誤差項の期待値ゼロ
# - 仮定2： パラメータ(母数)における線形性
# - 仮定3： 誤差項の条件付期待値がゼロ


# ＜目次＞
# 0 準備
# 1 誤差項の期待値ゼロの確認(仮定1)
# 2 パラメータにおける線形性(仮定2)
# 3 対数変換後の回帰係数の解釈
# 4 変数の線形性と母数の線形性の違い
# 5 多変量における診断方法
# 6 誤差項の条件付期待値ゼロ(仮定3)
# 7 不要な変数をモデルに取り入れる問題
# 8 中間変数をモデルに取り入れる問題


# 0 準備 ---------------------------------------------------------------------------

# ライブラリ
library(tidyverse)
library(magrittr)
library(broom)
library(car)
library(psych)
library(stargazer)
library(MASS)


# データロード
data07a <- read_csv("csv/data07a.csv")
data07b <- read_csv("csv/data07b.csv")
data07c <- read_csv("csv/data07c.csv")
data07d <- read_csv("csv/data07d.csv")


# 1 誤差項の期待値ゼロの確認(仮定1) ---------------------------------------------------

# ＜ポイント＞
# - 最小二乗法の誤差項の期待値がゼロとなるように切片が調整される
# - 以下では意図的に誤差項を0からシフトしているが、最小二乗法では誤差項の期待値が0となるように決定される


# データ作成
# --- y1, x1
# --- 誤差項(u)の期待値は0ではなく10となっている
set.seed(1)
a0 <- 1
b1 <- 1.5
x1 <- rnorm(n = 1000)
u1 <- rnorm(n = 1000, mean = 10, sd = 1)
y1 <- a0 + b1 * x1 + u1

# モデル構築
model1 <- lm(y1 ~ x1)

# サマリー
# --- 傾き(b0)の1.5は正しく推定できている（1.463378）
# --- u1のシフトを切片で吸収している（10.979510）
model1 %>% summary() %>% use_series(coefficient)

# 残差ヒストグラム
# --- 残差は10ではなく0を中心に分布
model1 %>% residuals() %>% hist()


# 2 パラメータにおける線形性(仮定2) ------------------------------------------------

# ＜ポイント＞
# - 最小二乗法はパラメータが線形であることを前提としている
#   --- 使用する系列の分布が正規分布である場合に実現する
#   --- 対数系列の場合はパラメータが非線形となる（散布図より確認）
# - 対数変換するなどして正規性を確保することで変数間の線形性を得ることができる場合もある


# データ確認
data07a %>% print()
data07a %>% summary()

# プロット作成
# --- 線形変換なし（ヒストグラムが偏っている：x2, y3, y4）
# --- 線形変換あり（ヒストグラムが正規分布に近くになっている）
data07a %>% select(x1, x2, y1, y3, y4) %>% pairs.panels()
data07a %>% transmute(x1, x2 = log(x2), y1, y3 = log(y3), y4 = log(y4)) %>% pairs.panels()

# 線形モデルの推定
# --- 系列の非線形性を無視してモデル構築
# --- モデル1のみ正規性の仮定が満たされている
model1 <- lm(y1 ~ x1, data = data07a)
model2 <- lm(y2 ~ x2, data = data07a)
model3 <- lm(y3 ~ x1, data = data07a)
model4 <- lm(y4 ~ x2, data = data07a)

# 回帰係数の確認
# --- モデル1のみb1=1.5を適切に推定することができている
stargazer(model1, model2, model3, model4, type = "text")


# 線形変換
# --- モデル2-4を対数変換してモデル5-7とする
model5 <- lm(y2 ~ log(x2), data = data07a)
model6 <- lm(log(y3) ~ x1, data = data07a)
model7 <- lm(log(y4) ~ log(x2), data = data07a)

# 回帰係数の確認
# --- いずれもb1=1.5を適切に推定することができている
stargazer(model1, model5, model6, model7, type = "text")


# 3 対数変換後の回帰係数の解釈 --------------------------------------------------------

# ＜ポイント＞
# - 対数変換後の回帰係数はパーセント変化を表している


# テイラー展開による近似 -------------

# データ定義
x1 <- 0.1

# テイラー展開は対数変換の近似値となる
# --- 対数変換
# --- テイラー展開
log(1 + x1)
x1 - (1 / 2 * x1 ^ 2) + (1 / 3 * x1 ^ 3) - (1 / 4 * x1 ^ 4)


# 変化率と対数の近似 ----------------

# データ定義
y0 <- 1.01
y1 <- 1.02

# 変化率
(y1 - y0) / y0

# 対数の場合
# --- 対数による変化率
# --- 対数差
log(y1 / y0)
log(y1) - log(y0)


# 4 変数の線形性と母数の線形性の違い --------------------------------------------------

# ＜ポイント＞
# - 式(7-10)のように残差を加算するモデルは線形変換することができない
#  --- 式(7-9)のような形式にしておく必要がある


# パラメータ設定
n1 <- 1000

# データ生成
# --- x3：一様乱数
# --- x4：一様乱数
# --- e1：正規乱数
set.seed(1)
x3 <- runif(n = n1)
x4 <- runif(n = n1)
e1 <- rnorm(n = n1)

# パラメータ設定
# --- 回帰係数の真値
b0 <- 1
b1 <- 0.6
b2 <- 0.4

# データ作成(Y)
y5 <- b0 * x3 ^ b1  * x4 ^ b2 * exp(e1)
y6 <- b0 * x3 ^ b1  * x4 ^ b2 + e1

# モデル構築
# --- 対数変換するかどうか、yはy5とy6（4パターン）
# --- モデル9が適切な線形変換を実行している
model8  <- lm(y5 ~ x3 + x4)
model9  <- lm(log(y5) ~ log(x3) + log(x4))
model10 <- lm(y6 ~ x3 + x4)
model11 <- lm(log(y6) ~ log(x3) + log(x4))

# 結果比較
# --- モデル9が適切に推定できている
stargazer(model8, model9, model10, model11, type = "text")


# 5 多変量における診断方法 -----------------------------------------------------------

# ＜ポイント＞
# - 回帰係数ごとに線形性を持つように変換することで適切なモデルを導くことが可能となる
#   --- 現実的には常に全てチェックするのは手間がかかる（変換候補は無数にある）
#   --- パラメータの線形性(仮定2)はハードルが高い仮定といえる


# データ確認
data07b %>% print()
data07b %>% summary()

# プロット作成
data07b %>% pairs.panels()

# モデル作成
model12 <- lm(y1 ~ x1 + x3, data = data07b)
model13 <- lm(y1 ~ log(x1) + log(x3), data = data07b)
model14 <- lm(log(y1) ~ x1 + x3, data = data07b)
model15 <- lm(log(y1) ~ log(x1) + log(x3), data = data07b)

# 残差プロット
# --- モデル14のx1が線形性がある
# --- モデル15のx1とx3が線形性がある
model12 %>% crPlots()
model13 %>% crPlots()
model14 %>% crPlots()
model15 %>% crPlots()

# 最終モデル
model16 <- lm(log(y1) ~ x1 + log(x3), data = data07b)
model16 %>% tidy()


# 6 誤差項の条件付期待値ゼロ(仮定3) ---------------------------------------------------

# ＜ポイント＞


# ＜インプリケーション＞
# - この仮定を満たすためには、必要な共変量をなるべく取り込場さないようにする


# 7 不要な変数をモデルに取り入れる問題 -------------------------------------------------

# ＜ポイント＞
# - 重回帰モデルに不要な変数を入れてもモデル精度や回帰係数には影響はない
#   --- 判断を迷う変数は入れてしまってよい
#   --- 信頼区間が広がってしまう弊害がある
#   --- 変数選択などで事前に不要な変数のあたりを付けておくのも一案


# データ確認
data07c %>% print()
data07c %>% summary()

# プロット作成
data07c %>% pairs.panels()

# モデル構築
# --- モデル19は不要な説明変数(x3)を含む
model17 <- lm(y1 ~ x1, data = data07c)
model18 <- lm(y1 ~ x1 + x2, data = data07c)
model19 <- lm(y1 ~ x1 + x2 + x3, data = data07c)

# 結果比較
# --- モデル19のR2の水準は特に悪化していない
stargazer(model17, model18, model19, type = "text")

# 信頼区間
# --- 不要な変数が入ることで信頼区間が必要以上に大きくなる可能性がある
model18 %>% confint()
model19 %>% confint()

# ステップワイズ回帰
# --- 赤池情報量基準による変数選択（因果推論では推奨されない）
# --- いずれもmodel18のモデルを選択する
stepAIC(model18)
stepAIC(model19)


# 8 中間変数をモデルに取り入れる問題 ---------------------------------------------------

# ＜ポイント＞
# - 中間変数に相当する変数はモデルに含めてはならない
# - 因果ダイアグラム(DAG)は本来P88であるはずが、P104のようにX1とX2の因果の向きが変わってしまう


# データ確認
data07d %>% print()
data07d %>% summary()

# プロット作成
data07d %>% pairs.panels()

# モデル構築
# --- モデル20：直接効果のみ
# --- モデル21：直接効果 + 間接効果
model20 <- lm(y1 ~ x1, data = data07d)
model21 <- lm(y1 ~ x1 + x2, data = data07d)

# 回帰係数
# --- x1の真値は3.1なのでモデル20は適切に推定できている
stargazer(model20, model21, type = "text")
